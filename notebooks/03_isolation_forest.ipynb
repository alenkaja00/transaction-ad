{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "DATASET = config['dataset']\n",
    "THRESHOLD = config['if_model']['threshold']\n",
    "\n",
    "DATASET_LOCATION = f\"../data/01-ibm-transactions-for-aml/feature_engineering/{DATASET}-features\"\n",
    "CASES_LOCATION = f\"../data/01-ibm-transactions-for-aml/preprocessed/{DATASET}-patterns/{DATASET}-cases.parquet\"\n",
    "GFP_FEATURES_LOCATION = f\"../data/01-ibm-transactions-for-aml/feature_engineering/{DATASET}-enriched\"\n",
    "\n",
    "NORMAL_OUTPUT = f\"../data/01-ibm-transactions-for-aml/filtered_output/normal\"\n",
    "NON_NORMAL_OUTPUT = f\"../data/01-ibm-transactions-for-aml/filtered_output/non_normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(DATASET_LOCATION)\n",
    "cases = pd.read_parquet(CASES_LOCATION)\n",
    "\n",
    "cases_columns = cases[['transaction_id', 'id']]\n",
    "data = data.merge(cases_columns, on='transaction_id', how='left')\n",
    "data['id'] = data['id'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "data[\"timestamp\"] = data[\"timestamp\"].values.astype(int) // 10**9\n",
    "min_timestamp = data[\"timestamp\"].min()\n",
    "data[\"timestamp\"] = data[\"timestamp\"] - min_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data = pd.read_parquet(GFP_FEATURES_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(enriched_data, on='transaction_id', how='left')\n",
    "data = data.sort_values(by=\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns=['target', 'source', 'target_bank', 'source_bank', 'transaction_id',\n",
    "'timestamp', 'source_currency', 'target_currency', 'source_amount', 'target_amount', 'format',\n",
    "'is_laundering', 'amount', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_columns = X_train.columns\n",
    "y_target = data[['transaction_id', 'id', 'is_laundering']].copy()\n",
    "y_target_columns = y_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target['is_case'] = np.where(y_target['id'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace([np.inf, -np.inf], 0)\n",
    "X_train = X_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=40)\n",
    "X_new = selector.fit_transform(X_train, y_target['is_laundering'])\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "\n",
    "X_training = X_train[selected_features]\n",
    "X_scaled_training = X_training\n",
    "\n",
    "print(\"X_train.shape=\", X_scaled_training.shape)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IsolationForest(n_estimators=200,\n",
    "                        max_samples=0.01, \n",
    "                        contamination=0.1, \n",
    "                        max_features=0.8, \n",
    "                        bootstrap=False, \n",
    "                        n_jobs=-1,\n",
    "                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_scaled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_scaled_training)\n",
    "scores = model.decision_function(X_scaled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_training = pd.DataFrame(X_scaled_training, columns=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = pd.concat([X_scaled_training, y_target], axis=1)\n",
    "eval[\"predictions\"] = predictions\n",
    "eval[\"scores\"] = -scores + 0.5\n",
    "\n",
    "# print(\"Cases\", eval[(eval['predictions'] == -1) & (eval['is_case'] == 1)].shape)\n",
    "# print(\"Laundering\", eval[(eval['predictions'] == -1) & (eval['is_laundering'] == 1)].shape)\n",
    "# print(\"True Negatives\", eval[(eval['predictions'] == 1) & (eval['is_laundering'] == 0)].shape)\n",
    "# print(\"False Positives\", eval[(eval['predictions'] == -1) & (eval['is_laundering'] == 0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP = eval[(eval['predictions'] == -1) & (eval['is_laundering'] == 1)].shape[0]\n",
    "# FN = eval[(eval['predictions'] == 1) & (eval['is_laundering'] == 1)].shape[0]\n",
    "# FP = eval[(eval['predictions'] == -1) & (eval['is_laundering'] == 0)].shape[0]\n",
    "# TN = eval[(eval['predictions'] == 1) & (eval['is_laundering'] == 0)].shape[0]\n",
    "\n",
    "# print(f\"True Positives: {TP}\")\n",
    "# print(f\"False Negatives: {FN}\")\n",
    "# print(f\"False Positives: {FP}\")\n",
    "# print(f\"True Negatives: {TN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = eval['scores'].quantile(THRESHOLD)\n",
    "print(threshold)\n",
    "\n",
    "new_scores = [1 if score>=threshold else 0 for score in eval['scores']]\n",
    "eval['new_scores'] = new_scores\n",
    "\n",
    "TP = eval[(eval['new_scores'] == 1) & (eval['is_laundering'] > 0)].shape[0]\n",
    "FN = eval[(eval['new_scores'] == 0) & (eval['is_laundering'] > 0)].shape[0]\n",
    "FP = eval[(eval['new_scores'] == 1) & (eval['id'] <= 0)].shape[0]\n",
    "TN = eval[(eval['new_scores'] == 0) & (eval['id'] <= 0)].shape[0]\n",
    "\n",
    "print(f\"True Positives: {TP}\")\n",
    "print(f\"False Negatives: {FN}\")\n",
    "print(f\"False Positives: {FP}\")\n",
    "print(f\"True Negatives: {TN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "normal_transactions = eval[eval['is_laundering'] == 0]\n",
    "plt.scatter(normal_transactions.index, normal_transactions['scores'], c='CornflowerBlue', s=20, label='Normal Transactions', alpha=0.6)\n",
    "laundering_transactions = eval[eval['is_laundering'] == 1]\n",
    "plt.scatter(laundering_transactions.index, laundering_transactions['scores'], c='DarkOrange', s=20, label='Laundering Transactions', alpha=0.6)\n",
    "\n",
    "plt.xlabel('Transactions')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "normal = eval[eval['is_case'] == 0]\n",
    "laundering = eval[eval['is_case'] == 1]\n",
    "\n",
    "ax1.hist(normal['scores'], bins=300, alpha=0.7, label='Normal Transactions', color='cornflowerblue')\n",
    "ax1.set_xlabel('Model Score')\n",
    "ax1.set_ylabel('Frequency (Normal Transactions)', color='cornflowerblue')\n",
    "ax1.tick_params(axis='y', labelcolor='cornflowerblue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.hist(laundering['scores'], bins=300, alpha=0.7, label='Laundering Transactions', color='goldenrod')\n",
    "ax2.set_ylabel('Frequency (Case Transactions)', color='goldenrod')\n",
    "ax2.tick_params(axis='y', labelcolor='goldenrod')\n",
    "\n",
    "plt.title('Model scores of Normal and Case Transactions')\n",
    "fig.tight_layout()\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = precision_score(eval['is_case'], eval['new_scores'])\n",
    "# recall = recall_score(eval['is_case'], eval['new_scores'])\n",
    "# f1 = f1_score(eval['is_case'], eval['new_scores'])\n",
    "# accuracy = accuracy_score(eval['is_case'], eval['new_scores'])\n",
    "\n",
    "# print(f\"Precision: {precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1: {f1}\")\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = roc_curve(eval['is_laundering'], eval['scores'])\n",
    "# roc_auc = roc_auc_score(eval['is_laundering'], eval['scores'])\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, color='blue', label=f'AUC = {roc_auc.round(2)}')\n",
    "# plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('FP Rate')\n",
    "# plt.ylabel('TP Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_cases = data[data['id']>0]['id'].nunique()\n",
    "# incomplete_cases = eval[(eval['new_scores'] == 0) & (eval['id']>0)]['id'].nunique()\n",
    "# print(f\"Anomalous identified cases: {total_cases-incomplete_cases}/{total_cases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# touched_cases = eval[(eval['new_scores'] == 1)&(eval['id']>0)]['id'].nunique()\n",
    "# print(f\"Cases touched by the model: {touched_cases}/{total_cases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_path = f\"{NORMAL_OUTPUT}_{DATASET}_{THRESHOLD}.csv\"\n",
    "non_normal_path = f\"{NON_NORMAL_OUTPUT}_{DATASET}_{THRESHOLD}.csv\"\n",
    "eval.query('new_scores == 0')['transaction_id'].to_csv(normal_path, index=False)\n",
    "eval.query('new_scores == 1')['transaction_id'].to_csv(non_normal_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
